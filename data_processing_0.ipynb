{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import utils\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate(word, ents_list, output):\n",
    "    for ents in ents_list:\n",
    "        if word.idx >= ents['start'] and word.idx < ents['end']:\n",
    "            if ents['count'] == 0:\n",
    "                o = \"{} {} {} {} {} {}\".format(word.text, \"B-\" + ents['type'], word.pos_, word.lemma_, word.tag_, word.dep_)\n",
    "                output.append(o)\n",
    "                ents['count'] += 1\n",
    "            else:\n",
    "                o = \"{} {} {} {} {} {}\".format(word.text, \"I-\" + ents['type'], word.pos_, word.lemma_, word.tag_, word.dep_)\n",
    "                output.append(o)\n",
    "            return output\n",
    "        \n",
    "    o = \"{} {} {} {} {} {}\".format(word.text, \"0\", word.pos_, word.lemma_, word.tag_, word.dep_)\n",
    "    output.append(o)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(filename, out_file):\n",
    "    ents_list = []\n",
    "    output = []\n",
    "    ## open file\n",
    "    with open(filename) as f:\n",
    "        if os.stat(filename).st_size != 0:\n",
    "            d = json.load(f)\n",
    "            doc = nlp(d[\"content\"]) ## content as the original text\n",
    "            hopper = d[\"cyberevent\"][\"hopper\"] ## hopper array\n",
    "            for h in hopper:\n",
    "                events = h[\"events\"] ## events array\n",
    "                for E in events:\n",
    "                    event_type = E[\"type\"] ## example=> type: Attack\n",
    "                    nugget = E[\"nugget\"]\n",
    "                    event_subtype = E[\"subtype\"] ## example=> subtype: Databreach\n",
    "                    if \"argument\" in E:\n",
    "                        arguments = E[\"argument\"] ## arguments array\n",
    "                        for T in arguments:\n",
    "                            t = T[\"type\"] ## example=> type: Organization or Person or System\n",
    "                            role_type = T[\"role\"][\"type\"] ## example=> type: Victim or Attacker or\n",
    "                            startOffset = T[\"startOffset\"]\n",
    "                            endOffset = T[\"endOffset\"]\n",
    "                            ents = {'type': role_type, 'start': startOffset, 'end':endOffset, 'count': 0}\n",
    "                            ents_list.append(ents)\n",
    "\n",
    "            for word in doc:\n",
    "                output = annotate(word, ents_list, output)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset():\n",
    "    directory = r'data/annotation/'\n",
    "    directory_output = 'data/annotation_j/'\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".json\"):\n",
    "            in_file = os.path.join(directory, filename)\n",
    "            out_file = os.path.join(directory_output, filename.split(\".\")[0] + \"_j.txt\")\n",
    "            print(in_file)\n",
    "            output = process_file(in_file, out_file)\n",
    "            with open(out_file, 'w') as filehandle:\n",
    "                filehandle.writelines(\"%s\\n\" % line for line in output)\n",
    "            print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
